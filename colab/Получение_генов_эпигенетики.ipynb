{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUk9mUkhI8Je"
      },
      "source": [
        "Устанавливаем HMMER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1E2ttARVSKuE"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "wget http://eddylab.org/software/hmmer/hmmer-3.3.2.tar.gz\n",
        "tar xf hmmer-3.3.2.tar.gz\n",
        "cd hmmer-3.3.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZjhG2leSWW9"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cd hmmer-3.3.2\n",
        "./configure\n",
        "make\n",
        "make install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr4NxI_9JFwA"
      },
      "source": [
        "Скачиваем Pfam\n",
        "По ftp доступны разны версии базы. Нас интересует последняя в формате hmm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfY1wB3oUvL6",
        "outputId": "733d83f9-b3b2-4682-a6f6-6b5374032a1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-15 19:13:53--  http://ftp.ebi.ac.uk/pub/databases/Pfam/releases/Pfam35.0/Pfam-A.hmm.gz\n",
            "Resolving ftp.ebi.ac.uk (ftp.ebi.ac.uk)... 193.62.193.165\n",
            "Connecting to ftp.ebi.ac.uk (ftp.ebi.ac.uk)|193.62.193.165|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 293000230 (279M) [application/x-gzip]\n",
            "Saving to: ‘Pfam-A.hmm.gz’\n",
            "\n",
            "Pfam-A.hmm.gz       100%[===================>] 279.43M   714KB/s    in 6m 49s  \n",
            "\n",
            "2024-06-15 19:20:42 (700 KB/s) - ‘Pfam-A.hmm.gz’ saved [293000230/293000230]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://ftp.ebi.ac.uk/pub/databases/Pfam/releases/Pfam35.0/Pfam-A.hmm.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWnlyTK9Jo0Q"
      },
      "source": [
        "Извлекаем из архива"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AXN716JmU-O0"
      },
      "outputs": [],
      "source": [
        "!gunzip Pfam-A.hmm.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHrwjpTlJtbd"
      },
      "source": [
        "Создаем нужные для hmmer'a файлы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abD_KzEBWVqB",
        "outputId": "f9ef2256-c2b7-4d69-fa70-271cffc12202"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working...    done.\n",
            "Pressed and indexed 19632 HMMs (19632 names and 19632 accessions).\n",
            "Models pressed into binary file:   Pfam-A.hmm.h3m\n",
            "SSI index for binary model file:   Pfam-A.hmm.h3i\n",
            "Profiles (MSV part) pressed into:  Pfam-A.hmm.h3f\n",
            "Profiles (remainder) pressed into: Pfam-A.hmm.h3p\n"
          ]
        }
      ],
      "source": [
        "!hmmpress Pfam-A.hmm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "h5ajvyOxoaS5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dd1a995-b64f-4ac3-b3d7-42b627152fe7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HMMER3/f [3.1b2 | February 2015]\n",
            "NAME  1-cysPrx_C\n",
            "ACC   PF10417.12\n",
            "DESC  C-terminal domain of 1-Cys peroxiredoxin\n",
            "LENG  40\n",
            "ALPH  amino\n",
            "RF    no\n",
            "MM    no\n",
            "CONS  yes\n",
            "CS    yes\n",
            "MAP   yes\n",
            "DATE  Thu Nov  4 19:20:02 2021\n",
            "NSEQ  40\n",
            "EFFN  17.426758\n",
            "CKSUM 4086680297\n",
            "GA    21.1 21.1;\n",
            "TC    21.1 21.1;\n",
            "NC    21 21;\n",
            "BM    hmmbuild HMM.ann SEED.ann\n",
            "SM    hmmsearch -Z 61295632 -E 1000 --cpu 4 HMM pfamseq\n",
            "STATS LOCAL MSV       -7.5463  0.71948\n",
            "STATS LOCAL VITERBI   -7.8624  0.71948\n",
            "STATS LOCAL FORWARD   -4.3303  0.71948\n",
            "HMM          A        C        D        E        F        G        H        I        K        L        M        N        P        Q        R        S        T        V        W        Y   \n",
            "            m->m     m->i     m->d     i->m     i->i     d->m     d->d\n",
            "  COMPO   2.28046  4.31208  2.83393  2.63913  3.90855  2.69988  3.89812  3.33401  2.56310  2.85023  3.99954  3.22924  2.52123  2.90328  3.31238  2.94055  2.70512  2.59551  3.49266  3.82715\n",
            "          2.68618  4.42225  2.77519  2.73123  3.46354  2.40513  3.72494  3.29354  2.67741  2.69355  4.24690  2.90347  2.73739  3.18146  2.89801  2.37887  2.77519  2.98518  4.58477  3.61503\n",
            "          0.00226  6.48754  7.20989  0.61958  0.77255  0.00000        *\n",
            "      1   0.29666  6.14436  6.78514  6.79783  7.06332  2.55785  7.22049  6.57837  6.66651  6.27638  3.28757  5.91223  5.83978  6.69238  6.58162  2.20136  4.83343  5.59959  8.41086  7.43107      1 A - - H\n",
            "          2.68618  4.42225  2.77519  2.73123  3.46354  2.40513  3.72494  3.29354  2.67741  2.69355  4.24690  2.90347  2.73739  3.18146  2.89801  2.37887  2.77519  2.98518  4.58477  3.61503\n",
            "          0.00226  6.48754  7.20989  0.61958  0.77255  0.48576  0.95510\n",
            "      2   4.59591  5.92009  6.57211  5.96147  1.92899  5.81035  6.10135  2.33093  5.75927  0.69439  2.86149  5.97820  6.07717  5.78793  5.72916  5.13924  4.81708  2.59612  3.18569  3.35842      2 l - - H\n",
            "          2.68618  4.42225  2.77519  2.73123  3.46354  2.40513  3.72494  3.29354  2.67741  2.69355  4.24690  2.90347  2.73739  3.18146  2.89801  2.37887  2.77519  2.98518  4.58477  3.61503\n",
            "          0.00226  6.48754  7.20989  0.61958  0.77255  0.48576  0.95510\n",
            "      3   4.81290  7.05274  3.71696  4.47757  6.60126  5.41623  3.72993  5.92180  2.06538  3.59487  6.10993  4.89014  5.75663  0.42291  2.54802  4.76779  4.95656  5.56452  7.24472  6.08615      3 Q - - H\n",
            "          2.68618  4.42225  2.77519  2.73123  3.46354  2.40513  3.72494  3.29354  2.67741  2.69355  4.24690  2.90347  2.73739  3.18146  2.89801  2.37887  2.77519  2.98518  4.58477  3.61503\n",
            "          0.00226  6.48754  7.20989  0.61958  0.77255  0.48576  0.95510\n",
            "      4   2.64100  5.28125  5.84007  3.33362  1.80025  5.06896  2.72827  3.71332  5.01717  1.75203  2.65498  5.22280  5.43290  5.15329  5.03455  4.37913  1.80041  2.31249  5.90246  2.63298      4 l - - H\n",
            "          2.68618  4.42225  2.77519  2.73123  3.46354  2.40513  3.72494  3.29354  2.67741  2.69355  4.24690  2.90347  2.73739  3.18146  2.89801  2.37887  2.77519  2.98518  4.58477  3.61503\n",
            "          0.00226  6.48754  7.20989  0.61958  0.77255  0.48576  0.95510\n"
          ]
        }
      ],
      "source": [
        "!head -n 40 Pfam-A.hmm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zL3sy2rvJ5Wl"
      },
      "source": [
        "Смотрим статистику"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5JS0hV7Z-Zq",
        "outputId": "5bb85e09-ad34-4ee2-955b-a78c14480174"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# hmmstat :: display summary statistics for a profile file\n",
            "# HMMER 3.3.2 (Nov 2020); http://hmmer.org/\n",
            "# Copyright (C) 2020 Howard Hughes Medical Institute.\n",
            "# Freely distributed under the BSD open source license.\n",
            "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "#\n",
            "# idx  name                 accession        nseq eff_nseq      M relent   info p relE compKL\n",
            "# ---- -------------------- ------------ -------- -------- ------ ------ ------ ------ ------\n",
            "1      1-cysPrx_C           PF10417.12         40    17.43     40   1.37   1.32   1.29   0.09\n",
            "2      120_Rick_ant         PF12574.11          2     0.45    238   0.59   0.60   0.52   0.02\n",
            "3      12TM_1               PF09847.12          7     2.28    449   0.59   0.62   0.51   0.09\n",
            "4      14-3-3               PF00244.23        149     2.50    222   0.59   0.59   0.52   0.05\n",
            "5      17kDa_Anti_2         PF16998.8           6     0.99    116   0.59   0.57   0.52   0.03\n",
            "6      2-Hacid_dh           PF00389.33         78     5.69    134   0.59   0.62   0.44   0.03\n",
            "7      2-Hacid_dh_C         PF02826.22        135     3.55    178   0.59   0.60   0.53   0.01\n",
            "8      2-oxoacid_dh         PF00198.26         70     3.33    233   0.59   0.61   0.53   0.02\n",
            "9      2-oxogl_dehyd_N      PF16078.8         208    11.82     41   1.34   1.23   1.33   0.13\n",
            "10     2-ph_phosp           PF04029.17        125     3.02    226   0.59   0.62   0.51   0.02\n",
            "11     2-thiour_desulf      PF04463.15        338     2.11    137   0.59   0.57   0.46   0.02\n",
            "12     23ISL                PF16620.8          16     1.48    162   0.59   0.61   0.54   0.07\n"
          ]
        }
      ],
      "source": [
        "!hmmstat Pfam-A.hmm.h3m | head -n 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBqiKE1AdaCY"
      },
      "source": [
        "The columns are:\n",
        "\n",
        "**idx**\n",
        "The index of this profile, numbering each on in the file starting from 1.\n",
        "\n",
        "**name**\n",
        "The name of the profile.\n",
        "\n",
        "**accession**\n",
        "The optional accession of the profile, or \"-\" if there is none.\n",
        "\n",
        "**nseq**\n",
        "The number of sequences that the profile was estimated from.\n",
        "\n",
        "**eff_nseq**\n",
        "The effective number of sequences that the profile was estimated from, after HMMER applied an effective sequence number calculation such as the default entropy weighting.\n",
        "\n",
        "**M**\n",
        "The length of the model in consensus residues (match states).\n",
        "\n",
        "**relent**\n",
        "Mean relative entropy per match state, in bits. This is the expected (mean) score per consensus position. This is what the default entropy-weighting method for effective sequence number estimation focuses on, so for default HMMER3 models, you expect this value to reflect the default target for entropy-weighting.\n",
        "\n",
        "**info**\n",
        "Mean information content per match state, in bits. Probably not useful. Information content is a slightly different calculation than relative entropy.\n",
        "\n",
        "**p relE**\n",
        "Mean positional relative entropy, in bits. This is a fancier version of the per-match-state relative entropy, taking into account the transition (insertion/deletion) probabilities; it may be a more accurate estimation of the average score contributed per model consensus position.\n",
        "\n",
        "**compKL**\n",
        "Kullback-Leibler distance between the model's overall average residue composition and the default background frequency distribution. The higher this number, the more biased the residue composition of the profile is. Highly biased profiles can slow the HMMER3 acceleration pipeline, by causing too many nonhomologous sequences to pass the filters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2N22F0eaKD4E"
      },
      "source": [
        "Индексируем файл"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CZAZX4yU-Tw",
        "outputId": "67846c9f-66f1-423c-bf49-16849348c18c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working...    done.\n",
            "Indexed 19632 HMMs (19632 names and 19632 accessions).\n",
            "SSI index written to file Pfam-A.hmm.h3m.ssi\n"
          ]
        }
      ],
      "source": [
        "!hmmfetch --index Pfam-A.hmm.h3m"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_file = 'input.txt'\n",
        "output_file = 'Pfam_domains.txt'\n",
        "\n",
        "# Открываем файл для чтения\n",
        "with open(input_file, 'r') as file:\n",
        "    # Считываем строки из файла\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Извлекаем все слова, начинающиеся с \"PF\" из каждой строки\n",
        "pf_words = []\n",
        "for line in lines:\n",
        "    words = line.replace(';', ' ').replace(',', ' ').split()  # Удаляем пунктуацию и разбиваем строку на слова\n",
        "    for word in words:\n",
        "        if word.startswith('PF'):\n",
        "            pf_words.append(word)\n",
        "\n",
        "# Записываем найденные слова в столбик в файл Pfam_domains.txt\n",
        "with open(output_file, 'w') as file:\n",
        "    for word in pf_words:\n",
        "        file.write(word + '\\n')\n",
        "\n",
        "print(\"Слова, начинающиеся с 'PF', успешно записаны в файл Pfam_domains.txt.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnDw60qqWJ41",
        "outputId": "693d43a6-aacf-4b1c-9b16-c0f7606a2d9e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слова, начинающиеся с 'PF', успешно записаны в файл Pfam_domains.txt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_file = 'Pfam_domains.txt'\n",
        "output_file = 'Unique_Pfam_domains.txt'\n",
        "\n",
        "# Считываем уникальные слова начинающиеся с \"PF\" из файла\n",
        "unique_pf_words = set()\n",
        "with open(input_file, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "    for line in lines:\n",
        "        word = line.strip()\n",
        "        unique_pf_words.add(word)\n",
        "\n",
        "# Записываем уникальные слова в файл Unique_Pfam_domains.txt\n",
        "with open(output_file, 'w') as file:\n",
        "    for word in unique_pf_words:\n",
        "        file.write(word + '\\n')\n",
        "\n",
        "print(\"Уникальные слова, начинающиеся с 'PF', успешно записаны в файл Unique_Pfam_domains.txt.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I936MKpsW4b2",
        "outputId": "fbaac5c9-2733-474d-ff1b-ff46d1a53a04"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Уникальные слова, начинающиеся с 'PF', успешно записаны в файл Unique_Pfam_domains.txt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnP4zCPwFKe4"
      },
      "source": [
        "Скачиваем протеом\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head protein.faa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Imb1Mi-ZkJ1G",
        "outputId": "74cf5f5f-ea12-4b56-e126-f73f19952e32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">XP_034419599.1 fam-b protein [Plasmodium berghei ANKA]\n",
            "MRISILKFVFFSIIICSFEYVKNELYFVNDRGIYLERDVINFKNNKILADVDNQFDFNEFYESTLSLASQLGDCIEGNKE\n",
            "IAYLQSIIDSHIKKHKENNTLPDLNNVDKKTKKLIDQLRKELEEIKKELNNKRSSEVEIQPIKDKIITKKNKNNSVSEQE\n",
            "DFKQLENEGNFLEINDDNFKDEYNEITSSSNYKKLKINRKLKKENKKLVKKFMVFMVSHFVILGSGGGYLILLVIPCMIS\n",
            "VIKNCWKSLKLSFKKSEI\n",
            ">XP_034419600.1 conserved rodent malaria protein, unknown function [Plasmodium berghei ANKA]\n",
            "MVPSSMINNDIPLAKNACVIRPKVKANLHISLKNRKNAKDGAANISHNLQNHVENRIKERSLYYAAKEKYYRNKGKKYDK\n",
            "LRQSVECGESRILKEYYHSRNRIKRCSRKHKKHNYEKCSVCKSLVQRYLVLGENANKIVEGINERTNDIMCNSICDTDPN\n",
            "SKMNELIKEETEEKYSTIKRITPTAPVRKFDIAENIKNNDITKLPKNESLDGLYINNEKDLDSYDLSNMKNIVLSHDKKL\n",
            "GDTYIISDKNIICDLENKVEQKGNNYPLVKCENQFNENQSCANIESNDISKKKHMYTIFTDLNVSEIIDLMNRKPSNITN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!hmmstat Pfam-A.hmm"
      ],
      "metadata": {
        "id": "FLIsZm4N4PLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!hmmsearch Z-alpha.hmm protein.faa"
      ],
      "metadata": {
        "id": "ZdVPXr7gZGAo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1699a773-ca32-4fa7-e66e-9d8c98bec0ae"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Error: File existence/permissions problem in trying to open HMM file Z-alpha.hmm.\n",
            "HMM file Z-alpha.hmm not found (nor an .h3m binary of it)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Поиск\n"
      ],
      "metadata": {
        "id": "gpcFmHOdb_o4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8MiRfA9cPSF"
      },
      "outputs": [],
      "source": [
        "!hmmsearch --tblout search.csv Pfam-A.hmm protein.faa"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Теперь надо фильтровать"
      ],
      "metadata": {
        "id": "B3L6dANWcHec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_domains(file_name):\n",
        "    \"\"\" Читает файл с уникальными доменами Pfam и возвращает их в виде множества. \"\"\"\n",
        "    with open(file_name, 'r') as file:\n",
        "        domains = {line.strip() for line in file}\n",
        "    return domains\n",
        "\n",
        "def filter_csv_by_domains(csv_file, domains, output_file):\n",
        "    \"\"\" Проверяет строки csv файла на наличие любого из доменов и записывает их в новый файл. \"\"\"\n",
        "    import csv\n",
        "\n",
        "    with open(csv_file, mode='r', newline='', encoding='utf-8') as inp_file, \\\n",
        "         open(output_file, mode='w', newline='', encoding='utf-8') as out_file:\n",
        "        reader = csv.reader(inp_file)\n",
        "        writer = csv.writer(out_file)\n",
        "\n",
        "        for row in reader:\n",
        "            row_text = ','.join(row)  # Преобразуем строку списка в одну строчку текста\n",
        "            if any(domain in row_text for domain in domains):\n",
        "                writer.writerow(row)\n",
        "\n",
        "def main():\n",
        "    domains_file = 'Unique_Pfam_domains.txt'\n",
        "    source_csv_file = 'search.csv'\n",
        "    output_csv_file = 'filtered_results.csv'\n",
        "\n",
        "    # Загрузка уникальных доменов Pfam из файла\n",
        "    domains = read_domains(domains_file)\n",
        "\n",
        "    # Фильтрация CSV файла\n",
        "    filter_csv_by_domains(source_csv_file, domains, output_csv_file)\n",
        "    print(\"Фильтрация завершена, результаты записаны в\", output_csv_file)\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXpnlrdJaKGo",
        "outputId": "51c2c0ea-c447-4f75-b5d6-ab1383c8e47e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Фильтрация завершена, результаты записаны в filtered_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "def process_filtered_results(input_csv, output_file):\n",
        "\n",
        "    with open(input_csv, mode='r', newline='', encoding='utf-8') as inp_file, \\\n",
        "         open(output_file, mode='w', newline='', encoding='utf-8') as out_file:\n",
        "        reader = csv.reader(inp_file)\n",
        "        writer = csv.writer(out_file)\n",
        "\n",
        "        writer.writerow(['Id','Gene', 'Family'])  # Записываем заголовки столбцов\n",
        "\n",
        "        for row in reader:\n",
        "            row_text = ' '.join(row)  # Соединяем строку, если она разделена запятой\n",
        "            elements = row_text.split()  # Делим строку по пробелам\n",
        "            if len(elements) >= 4:  # Проверяем, есть ли минимум 4 элемента\n",
        "                id = elements[0] # Первый элемент - id\n",
        "                gene = elements[2]  # Третий элемент\n",
        "                family = elements[3]  # Четвертый элемент\n",
        "                writer.writerow([id, gene, family])  # Записываем в файл\n",
        "\n",
        "def main():\n",
        "    filtered_csv_file = 'filtered_results.csv'\n",
        "    output_csv_file = 'gene_family_results.csv'\n",
        "\n",
        "    # Обработка полученных результатов и запись в новый файл\n",
        "    process_filtered_results(filtered_csv_file, output_csv_file)\n",
        "    print(\"Обработка завершена, результаты записаны в\", output_csv_file)\n",
        "\n",
        "main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emBSikyknhCA",
        "outputId": "2c400339-f506-4573-83ca-8ae8aeeb034f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обработка завершена, результаты записаны в gene_family_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_duplicates(input_csv, output_csv):\n",
        "    import csv\n",
        "    unique_genes = {}  # Словарь для хранения уникальных генов и их семейств\n",
        "\n",
        "    with open(input_csv, mode='r', newline='', encoding='utf-8') as inp_file:\n",
        "        reader = csv.reader(inp_file)\n",
        "        header = next(reader, None)  # Пропускаем заголовок\n",
        "\n",
        "        for row in reader:\n",
        "            gene = row[0]\n",
        "            family = row[1]\n",
        "            if gene not in unique_genes:  # Если ген не в повторяющихся, добавляем его\n",
        "                unique_genes[gene] = family\n",
        "\n",
        "    with open(output_csv, mode='w', newline='', encoding='utf-8') as out_file:\n",
        "        writer = csv.writer(out_file)\n",
        "        writer.writerow(header)  # Записываем заголовки столбцов\n",
        "        for gene, family in unique_genes.items():\n",
        "            writer.writerow([gene, family])  # Записываем уникальные пары ген-семейство\n",
        "\n",
        "def main():\n",
        "    input_csv_file = 'gene_family_results.csv'\n",
        "    output_csv_file = 'unique_gene_family_results.csv'\n",
        "\n",
        "    # Удаление дубликатов по полю ген и запись в новый файл\n",
        "    remove_duplicates(input_csv_file, output_csv_file)\n",
        "    print(\"Дубликаты удалены, результаты записаны в\", output_csv_file)\n",
        "\n",
        "main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gv7eFQmqoHOv",
        "outputId": "5240be28-47c1-4668-acea-bd0eb747ff6e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Дубликаты удалены, результаты записаны в unique_gene_family_results.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}